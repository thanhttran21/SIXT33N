{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIXT33N Phase 4: SVD/PCA \n",
    "\n",
    "### EECS16B: Designing Information Devices and Systems II, Spring 2021\n",
    "\n",
    "Written by Nathaniel Mailoa and Emily Naviasky (2016), Updated by Julian Chan (2018), Peter Schafhalter (2019), Zhongkai Wang (2021).\n",
    "\n",
    "nmailoa@berkeley.edu &emsp; enaviasky@berkeley.edu &emsp; julianchan0928@berkeley.edu &emsp; pschafhalter@berkeley.edu; zhongkai@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction / Lab Note](#intro)\n",
    "\n",
    "### Project Part 4A\n",
    "* [Part 0: Preparing your Launchpad](#part0)\n",
    "* [Part 1: Setting up your Circuit](#part1)\n",
    "* [Part 2: Data Collection](#part2)\n",
    "* [Part 3: Data Preprocessing](#part3)\n",
    "\n",
    "### Project Part 4B\n",
    "* [Part 4: PCA via SVD](#part4)\n",
    "* [Part 5: Clustering Data Points](#part5)\n",
    "* [Part 6: Testing your Classifier](#part6)\n",
    "* [Appendix: Formatting Vectors for Energia](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "SIXT33N is an obedient little robot that will follow the directions that you tell it. There are four moves that SIXT33N can make: move straight, move straight slowly, turn right, and turn left. However, SIXT33N does not speak human languages, and some words, like \"left\" and \"right\", sound very similar (a strong single syllable), while other words are easy to distinguish. Your job in this phase is to find four command words that are easy for SIXT33N to tell apart (consider syllables and intonation).\n",
    "\n",
    "For phase 2, you will develop the PCA classifier that allows SIXT33N to tell the difference between the four commands. You will examine several different words and determine which ones will be easiest to classify by PCA.\n",
    "\n",
    "**For more background on the connection between SVD and PCA, please read the [lab note](https://drive.google.com/file/d/1QIw3SNX7EzQVDhX3PZQ-YvfGpZlDqzNm/view?usp=sharing).**\n",
    "\n",
    "### Side Note: Datasets in Machine Learning Applications\n",
    "It is common practice, especially in machine learning applications, to split a dataset into a training set and a smaller test set (some common ratios for train:test are 80:20 or 70:30) when trying to make data-driven predictions/decisions. In this lab, we will collect data and split our dataset into 70% training data and 30% test data. \n",
    "\n",
    "### Overview of Classification Procedure\n",
    "Once you have some sample data collected, we will:\n",
    "1. Split our data into 2 sets: train_data and test_data\n",
    "2. Perform PCA and look at how well it separates the train_data \n",
    "3. Once you have a set of four words that you like, you will compute the means for each of those four words in the PCA basis. We will classify each word according to which mean it is closest in Euclidean distance to. \n",
    "4. To see how well our classifier does on data it has never seen before (this is called generalization in machine learning), we will project test_data onto the same PCA basis as train_data, and find the mean that is closest in Euclidean distance to each data point. \n",
    "\n",
    "<b>\n",
    "The goals of this phase are as follows:\n",
    "- Generate envelope and utilize threshold to get snippets\n",
    "- PCA + Classifier (4 commands)\n",
    "- Check accuracy\n",
    "- PCA projection on Launchpad\n",
    "</b>\n",
    "\n",
    "The checkpoints (marked **<span style=\"color:green\">green</span>** in the Notebook) are:\n",
    "- Checkpoint 1: First pass through PCA with training data; GSI feedback\n",
    "- Checkpoint 2: Classification target met in Python using test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When humans distinguish words, they listen for temporal and frequency differences to determine what is being said. However, SIXT33N does not have the memory or the processing power to distinguish words nearly as well as our human brains, so we will have to choose much simpler features for SIXT33N to look at (syllables, intonation, magnitude).\n",
    "\n",
    "When you think of speech signals, you might notice that the shape of the speech wave is a very distinctive part of each word. Taking just the shape of the magnitude of a signal is called enveloping, exemplified in the image below. So, we want to do some filtering to retrieve the envelope of the audio signal. We train the PCA off of just this envelope and build a classifier to classify new data points.\n",
    "\n",
    "<center>\n",
    "<img width=\"400px\" src=\"images/proj-envelope.png\">\n",
    "</center>\n",
    "\n",
    "<b>Keeping in mind that the words that look most different have different shapes (or different amplitudes varied over time), brainstorm at least 6 words that you think will sort well. Consider syllables, intonation, and length of the word.</b>\n",
    "\n",
    "**<span style=\"color:red\">What words are you going to try? Why?</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Good\" audio data has a high signal to noise ratio. Recording words while far away from the microphone may cause your intended word to blend in with background noise. However, \"oversaturation\" of the audio signal (speaking too loudly and/or too closely into the mic) will distort the signal (Why?). You can use the `oscope.ino` on the microphone output to test for over/under saturation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part0'></a>\n",
    "## <span style=\"color:navy\">Part 0: Preparing your Launchpad</span>\n",
    "\n",
    "**Disconnect the 5V jumper wire that's powering the MSP through the 9V Battery and 9V -> 5V regulator**. As before, make sure that the MSP is not simultaneously being powered by both the computer (via the USB) and the 9V battery. Otherwise, you risk frying your MSP.\n",
    "\n",
    "For the remainder of this lab, the MSP can be powered by only the computer, via the USB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## <span style=\"color:navy\">Part 1: Setting up your Circuit</span>\n",
    "\n",
    "### Materials\n",
    "- Microphone front-end circuit\n",
    "- Launchpad + USB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='calibration'></a>\n",
    "### 1.1. Calibrating your Launchpad to the Mic Board\n",
    "\n",
    "#### Materials:\n",
    "- Mic board\n",
    "- Launchpad\n",
    "- USB cable\n",
    "- Jumper wires\n",
    "\n",
    "#### Tasks:\n",
    "\n",
    "1. Open up `oscope.ino` in Energia\n",
    "\n",
    "2. Measure the output of your 3.3V rail **with your multimeter** and record that voltage next to the `#define MAX_VOLTAGE`  directive at the top of the `oscope.ino` file.\n",
    "\n",
    "3. ~~Connect the calibration pin (`P6.2`) to your 3.3V rail.~~ **Remove the calibration pin from your breadboard and launchpad.** We will be using a predetermined calibration value from now on, as the drop in accuracy is almost negligible for our purposes.\n",
    "\n",
    "4. Make sure your Launchpad's probe pin (`P6.0`) is connected to the **output of your micboard (`MIC_OUT`)**. Check that the values look reasonable. Remember, the plotting for the `P6.0` is shifted down by ~1.65V to make it easier to figure out peak to peak. _Hint: What should the micboard's output be centered around? What are its max and min values? Review the mic board note if you're uncertain._\n",
    "\n",
    "5. Make sure your Launchpad's ground pin (`GND`) is connected to your breadboard's ground rail.\n",
    "\n",
    "6. Upload `oscope.ino` to your Launchpad.\n",
    "\n",
    "7. Open the serial plotter, set the baud rate to 9600 and hit `RST`.\n",
    "\n",
    "Notes:\n",
    "\n",
    "1. If the output of your micboard doesn't look right, make sure the voltages at the different nodes of the micboard are correct. (ie OS1 = ~1.6-1.7V, OS2 = ~1.7V, VDD = 3.3V, etc).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tuning'></a>\n",
    "### 1.2. Tune Your Mic Board\n",
    "\n",
    "#### Materials:\n",
    "- Phone speaker or headphones\n",
    "- 6pc. Precision Screwdriver Set\n",
    "\n",
    "#### Tasks:\n",
    "1. Make sure `P6.0` is connected to `MIC_OUT`.\n",
    "\n",
    "- **Play a pure tone using a [tone generator](https://www.szynalski.com/tone-generator/) in the range (3000 - 4000 Hz)** on your phone at a reasonable volume. Do NOT use a Youtube video!\n",
    "    - If the tone generator website is not working for you, you can download a tone generator app onto your phone instead.\n",
    "\n",
    "- Make sure to point the speaker directly at the mic and hold it a few inches away from the mic. \n",
    "    - The distance between your speaker and the mic affects the tuning process quite a bit so **try to keep your speaker at a fixed distance from your mic**.\n",
    "\n",
    "- Turn the potentiometer **(CW: decrease gain | CCW: increase gain)** until you see a sine wave with a **peak-to-peak of around 2V to 3V** on the serial plotter.\n",
    "\n",
    "- Stop playing the tone, and speak into the microphone from a few inches away from the micboard. You should see it pick up your voice reasonably well.\n",
    "\n",
    "- Move `P6.0` to the output of your low-pass filter. Make sure that when you're speaking, you're still seeing a decent response from this filtered version of the mic board output.\n",
    "\n",
    "#### Notes/Tips:\n",
    "\n",
    "<img style=\"width:600px\" src=\"images/sp21_railing_example.png\">\n",
    "\n",
    "- With oscillating signals like this, there is an important concept called \"railing.\" We define railing, with regards to this mic board, as non-linear behavior at the boundaries of the output range as shown in the plot. In general, if `P2P` on the serial plotter is too high ($>3.0V$ in testing) your micboard is probably railing. Keep this in mind as you tune your mic and as you go through the rest of the lab.\n",
    "- <span style=\"color:red\">NOTE: The above graph is an example of railing behavior. DO NOT attempt to try to match this perfectly; this is an example of what behavior you should avoid, where the signal starts to get flattened towards the edges of its amplitude.</span>\n",
    "- The plotter has a legend at the top telling you which lines correspond to the mic board output, the peak-to-peak, and the 2.5V threshold.\n",
    "- The mic board's output plot is centered around zero (0) to make reading the peak-to-peak more convenient. This does not reflect the actual DC value of its center, which is generated by the biasing circuitry from part 1.2.\n",
    "- The instantaneous peak-to-peak value is given beside its legend title.\n",
    "- If you tap on the mic, it may rail, but **it should not be railing while you play the tone or speak.** \n",
    "    \n",
    "<span style=\"color:red\">**Congratulations! You have successfully tuned your mic board!**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## <span style=\"color:navy\">Part 2: Data Collection</span>\n",
    "\n",
    "### Materials\n",
    "- Microphone front-end circuit\n",
    "- Launchpad + USB\n",
    "- Python\n",
    "    - Numpy\n",
    "    - Matplotlib\n",
    "    - Pyserial\n",
    "    \n",
    "### Setup\n",
    "\n",
    "#### Python\n",
    "For this lab you will need to have Python and the 3 listed libraries installed on your local machine. If you do not already have Python or these libraries installed, follow the instructions in [this Piazza post](https://piazza.com/class/kj9duntmc4w7ib?cid=1820). You should have the libraries listed under \"Materials\" above before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "#### Data Collection \n",
    "\n",
    "Now we will record 30 audio samples for each of your minimum of 6 chosen words.\n",
    "\n",
    "**<span style=\"color:red\">Move `P6.0` to the output of your low-pass filter for your mic board circuit. We are interested in the low-pass filtered version of the micboard output.</span>**\n",
    "\n",
    "**For each chosen word, do the following:**\n",
    "1. Upload the sketch **`collect-data-envelope.ino`** to your Launchpad.\n",
    "    - This sketch records 2 seconds of audio sampled every 0.35ms at a time and sends it to your computer.\n",
    "    - When the red LED is on, the Launchpad is recording audio.\n",
    "2. Run **`python collect-data-envelope.py YOUR_WORD.csv`**.\n",
    "    - In your terminal, navigate to the directory with the `collect-data-envelope.py` script and then run the above command.\n",
    "    - Make sure the serial monitor/plotter in Energia is closed before running the script!\n",
    "    - This program will capture audio data collected by the Launchpad and write it to `YOUR_WORD.csv` (replace the \"YOUR_WORD\" with whatever your word is).\n",
    "    - Choose your words carefully! Think about the PCA algorithm and what characterstics of your word might affect its output. See the guidelines we provided you in the slides.\n",
    "    - After you collect a few test words check `YOUR_WORD.csv` and make sure that it looks like a sound wave as opposed to being full of 0s. *It might help to plot the data in Excel.*\n",
    "3. **When the red light goes on, say the word you want to record.**\n",
    "    - **Pronounce the word consistently and always speak around the same time relative to when the red light turns on.** This will help you collect data that is less \"noisy\" which will result in better classification.\n",
    "    - The red LED on the Launchpad is like a recording room. When the red light goes on, the Launchpad is recording. Say the word you want to record before the red LED turns off.\n",
    "4. Once you've recorded 30 audio samples of the word, stop the python program (e.g. by pressing Ctrl + C in the command prompt).\n",
    "\n",
    "\n",
    "### Before moving on, please note that:\n",
    "\n",
    "You may realize in the next lab that one or two of your words are not sorting quite as well as you would like. Don't be afraid to come back to this section and try collecting different words based on what you have learned makes a word sortable. Recording more than the number of words used now will enable you to swap out words immediately, rather than have to recollect more later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "## <span style=\"color:navy\">Part 3: Data Preprocessing</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use the recorded data for PCA, we must first process the data. It is not necessary for you to understand the enveloping function well enough to implement it (since we have already done it for you), but just in case you are curious the enveloping function is described in the following pseudocode:\n",
    "\n",
    "<code><b>Enveloping function</b>\n",
    "Divide the whole signal to a block of 16 samples\n",
    "For each chunk:\n",
    "    Find the mean of the chunk\n",
    "    Subtract each sample by the mean\n",
    "    Find the sum of the absolute value of each sample\n",
    "</code>\n",
    "\n",
    "What you really need to know, however, is what the enveloped signal looks like for each word. Spend a little time looking at the data you just collected in the Python plots below.\n",
    "\n",
    "\n",
    "### 3.1 Load Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import csv\n",
    "import utils\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "# YOUR CODE HERE: fill in the path to the CSV file\n",
    "word1_raw = utils.read_csv(\"\")\n",
    "word2_raw = utils.read_csv(\"\")\n",
    "word3_raw = utils.read_csv(\"\")\n",
    "word4_raw = utils.read_csv(\"\")\n",
    "\n",
    "# Split the data into training and test set\n",
    "train_test_split_ratio = 0.7\n",
    "word1_raw_train, word1_raw_test = utils.train_test_split(word1_raw, train_test_split_ratio)\n",
    "word2_raw_train, word2_raw_test = utils.train_test_split(word2_raw, train_test_split_ratio)\n",
    "word3_raw_train, word3_raw_test = utils.train_test_split(word3_raw, train_test_split_ratio)\n",
    "word4_raw_train, word4_raw_test = utils.train_test_split(word4_raw, train_test_split_ratio)\n",
    "\n",
    "# Take the same number of readings for all words to be fair\n",
    "num_samples_train = min(np.shape(word1_raw_train)[0], np.shape(word2_raw_train)[0], np.shape(word3_raw_train)[0], np.shape(word4_raw_train)[0])\n",
    "word1_raw_train = word1_raw_train[:num_samples_train,:]\n",
    "word2_raw_train = word2_raw_train[:num_samples_train,:]\n",
    "word3_raw_train = word3_raw_train[:num_samples_train,:]\n",
    "word4_raw_train = word4_raw_train[:num_samples_train,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your data and get a feel for how it looks enveloped.\n",
    "\n",
    "**<span style=\"color:red\">Important: It's okay if the data isn't aligned. The code in the next part will automatically align the data.</span>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot all training samples\n",
    "plt.plot(word1_raw_train.T)\n",
    "plt.show()\n",
    "plt.plot(word2_raw_train.T)\n",
    "plt.show()\n",
    "plt.plot(word3_raw_train.T)\n",
    "plt.show()\n",
    "plt.plot(word4_raw_train.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Align Audio Recordings\n",
    "\n",
    "As you can see above, the speech is only a small part of the 2 second window, and each sample starts at different times. PCA is not good at interpreting delay, so we need to somehow start in the same place each time and capture a smaller segment of the 2 second sample where the speech is present. To do this, we will use a thresholding algorithm.\n",
    "\n",
    "First, we define a **`threshold`** relative to the maximum value of the data. We say that any signal that crosses the threshold is the start of a speech command. In order to not lose the first couple samples of the speech command, we say that the command starts **`pre_length`** samples before the threshold is crossed. We then take a window of the data that is **`length`** long, and try to capture the entire sound of the command in that window.\n",
    "\n",
    "<b>Play around with the parameters `length`, `pre_length` and `threshold`</b> in the cells below to find appropriate values corresponding to your voice and chosen commands. You should see the results and how much of your command you captured in the plots generated below. When you are satisfied, note down the values of `length`, `pre_length` and `threshold` - <b>you will need to add them to the Launchpad sketch later.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_snippets(data, length, pre_length, threshold):\n",
    "    \"\"\"Attempts to align audio samples in data.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): Matrix where each row corresponds to a recording's audio samples.\n",
    "        length (int): The length of each aligned audio snippet.\n",
    "        pre_length (int): The number of samples to include before the threshold is first crossed.\n",
    "        threshold (float): Used to find the start of the speech command. The speech command begins where the\n",
    "            magnitude of the audio sample is greater than (threshold * max(samples)).\n",
    "    \n",
    "    Returns:\n",
    "        Matrix of aligned recordings.\n",
    "    \"\"\"\n",
    "    assert isinstance(data, np.ndarray) and len(data.shape) == 2, \"'data' must be a 2D matrix\"\n",
    "    assert isinstance(length, int) and length > 0, \"'length' of snippet must be an integer greater than 0\"\n",
    "    assert 0 <= threshold <= 1, \"'threshold' must be between 0 and 1\"\n",
    "    snippets = []\n",
    "\n",
    "    # Iterate over the rows in data\n",
    "    for recording in data:\n",
    "        # Find the threshold\n",
    "        recording_threshold = threshold * np.max(recording)\n",
    "\n",
    "        # Figure out when interesting snippet starts\n",
    "        i = pre_length\n",
    "        while recording[i] < recording_threshold:\n",
    "            i += 1\n",
    "            \n",
    "        snippet_start = min(i - pre_length, len(recording) - length)\n",
    "        snippet = recording[snippet_start:snippet_start + length]\n",
    "\n",
    "        # Normalization\n",
    "        snippet = snippet / np.sum(snippet)\n",
    "        \n",
    "        snippets.append(snippet)\n",
    "\n",
    "    return np.vstack(snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 80 # Default: 80        # Adjust this\n",
    "pre_length = 5 # Default: 5     # Adjust this\n",
    "threshold = 0.5 # Default:  0.5    # Adjust this\n",
    "\n",
    "word1_processed_train = get_snippets(word1_raw_train, length, pre_length, threshold)\n",
    "plt.plot(word1_processed_train.T)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "word2_processed_train = get_snippets(word2_raw_train, length, pre_length, threshold)\n",
    "plt.plot(word2_processed_train.T)\n",
    "plt.show()\n",
    "word3_processed_train = get_snippets(word3_raw_train, length, pre_length, threshold)\n",
    "plt.plot(word3_processed_train.T)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "word4_processed_train = get_snippets(word4_raw_train, length, pre_length, threshold)\n",
    "plt.plot(word4_processed_train.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a mostly organized set of samples for each word. Can you tell the which word is which just by the envelope? Can you tell them apart? If you can't tell the words apart, then PCA will have a difficult time as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> STOP: END OF PROJECT PART 4A </span>\n",
    "**<span style=\"color:green\">This is the end of Project Part 4A: SVD/PCA Part 1. Submit a checkoff request for Part 4A. Next week in Project Part 4B we'll be implementing the PCA (Principal Component Analysis) algorithm via SVD (Singular Value Decomposition)!</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part4'></a>\n",
    "## <span style=\"color:navy\">Part 4: PCA via SVD</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 SVD/PCA Resources\n",
    "- http://www.ams.org/publicoutreach/feature-column/fcarc-svd\n",
    "- https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues\n",
    "- https://towardsdatascience.com/pca-and-svd-explained-with-numpy-5d13b0d2a4d8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Generate and Preprocess PCA Matrix\n",
    "\n",
    "Now that we have our data in a nice format, we can build the PCA input data matrix from that data by **stacking all the data vertically**. The function <b>`np.vstack`</b> might be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "processed_A = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of PCA is zero-mean your data as `demeaned_A`. Centering the data can be helpful to obtain principal components that are representative of the shape of the variations in the data. Please note that you want to **get the mean of each feature** ( _what are the features?_ ). The function `np.mean` might be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero-mean the matrix A\n",
    "# YOUR CODE HERE\n",
    "mean_vec = ...\n",
    "demeaned_A = ...\n",
    "print(processed_A.shape)\n",
    "print(mean_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the SVD of matrix demeaned_A\n",
    "# YOUR CODE HERE #\n",
    "U, S, Vt = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at your sigma values. They should show you very clearly how many principal components you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot out the sigma values (Hint: Use plt.stem for a stem plot)\n",
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">How many principal components do you need? Given that you are sorting 4 words, what is the the number you expect to need?</span>** \n",
    "\n",
    "There is no correct answer here. We can pick as many principal components onto which we project our data to get the \"best\" separation (most variance), but at some point, the cost-benefit isn't worth selecting an extra basis vector. For example, in our project, we are loading these basis vectors onto the [MSP430 Launchpad](http://www.ti.com/tool/MSP-EXP430F5529LP), and we can only store 2, maybe 3, principal components before we run into memory issues. For this reason, we encourage you to **choose only 2 principal components to use, with 3 being the maximum if necessary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Choosing a Basis using Principle Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `new_basis` variable to be a basis of these principal components. (*Hint: Of the three outputs from the SVD function call, which one will contain the principal components onto which we want to project our data points?*)\n",
    "\n",
    "When you plot `new_basis` you should see a number of line plots equal to the number of principal components you've chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the principal component(s)\n",
    "# YOUR CODE HERE\n",
    "new_basis = ...        # This should be the basis containing your principal components\n",
    "plt.plot(new_basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now project the data in the matrix A onto the new basis and plot it. Do you see clustering? Do you think you can separate the data easily? If not, you might need to try new words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_3D(ax,data, view_from_top=False, m = 'o', si = 20):\n",
    "    colors = ['blue', 'red', 'green', 'orange']\n",
    "    for dat, color in zip(data, colors):\n",
    "        Axes3D.scatter(ax, *dat.T, c=color, marker = m, s=si)\n",
    "    if view_from_top:\n",
    "        ax.view_init(elev=90.,azim=0)  # Move perspective to view from top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Project the data onto the new basis\n",
    "# YOUR CODE HERE\n",
    "proj = ...\n",
    "\n",
    "'''Uncomment this block for 3 basis vectors \n",
    "fig=plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_3D(ax,[proj[:num_samples_train], proj[num_samples_train:2*num_samples_train], proj[2*num_samples_train:3*num_samples_train], proj[3*num_samples_train:4*num_samples_train]])\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(10,7))\n",
    "plt.scatter(proj[0:num_samples_train,0], proj[0:num_samples_train,1], c=['blue'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_train:num_samples_train*2,0], proj[num_samples_train:num_samples_train*2,1], c=['red'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_train*2:num_samples_train*3,0], proj[num_samples_train*2:num_samples_train*3,1], c=['green'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_train*3:num_samples_train*4,0], proj[num_samples_train*3:num_samples_train*4,1], c=['orange'], edgecolor='none')\n",
    "plt.legend(['word1', 'word2', 'word3', 'word4'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your data might look noisy, and might not classify perfectly. That is completely okay, we are just looking for good enough. Like many AI applications, this is noisy data that we are classifying so some error in classification is okay. The important part is if you think that you can see some clustering. \n",
    "\n",
    "Once you think you have decent clustering, you can move on to getting your code to automate classification and you will make up for some of the error there, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part5'></a>\n",
    "## <span style=\"color:navy\">Part 5: Clustering Data Points</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement `find_centroids` which finds the center of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_centroids(clustered_data):\n",
    "    \"\"\"Find the center of each cluster by taking the mean of all points in a cluster.\n",
    "    It may be helpful to recall how you constructed the data matrix (e.g. which rows correspond to which word)\n",
    "    \n",
    "    Parameters:\n",
    "        clustered_data: the data already projected onto the new basis\n",
    "        \n",
    "    Returns: \n",
    "        The centroids of the clusters\n",
    "    \"\"\"\n",
    "    centroids = []\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine the centroids of each cluster\n",
    "# YOUR CODE HERE\n",
    "centroids = ...\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroid1 = centroids[0]\n",
    "centroid2 = centroids[1]\n",
    "centroid3 = centroids[2]\n",
    "centroid4 = centroids[3]\n",
    "centroid_list = np.vstack([centroid1, centroid2, centroid3, centroid4])\n",
    "\n",
    "print('The first centroid is at: ' + str(centroid1))\n",
    "print('The second centroid is at: ' + str(centroid2))\n",
    "print('The third centroid is at: ' + str(centroid3))\n",
    "print('The fourth centroid is at: ' + str(centroid4))\n",
    "\n",
    "''' Uncomment this for 3 basis vectors: \n",
    "fig=plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_3D(ax,[proj[:num_samples_train], proj[num_samples_train:2*num_samples_train], proj[2*num_samples_train:3*num_samples_train], proj[3*num_samples_train:4*num_samples_train]], view_from_top=False)\n",
    "plot_3D(ax,[np.array([centroids[0]]), np.array([centroids[1]]), np.array([centroids[2]]), np.array([centroids[3]])], False, '*', 300)\n",
    "fig.show\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(10,7))\n",
    "plt.scatter(proj[0:num_samples_train,0], proj[0:num_samples_train,1], c=['blue'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_train:num_samples_train*2,0], proj[num_samples_train:num_samples_train*2,1], c=['red'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_train*2:num_samples_train*3,0], proj[num_samples_train*2:num_samples_train*3,1], c=['green'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_train*3:num_samples_train*4,0], proj[num_samples_train*3:num_samples_train*4,1], c=['orange'], edgecolor='none')\n",
    "\n",
    "plt.scatter(centroid_list[:,0], centroid_list[:,1], c=['blue', 'red', 'green', 'orange'], marker='*', s=300)\n",
    "plt.legend(['word1', 'word2', 'word3', 'word4'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Training Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part6'></a>\n",
    "## <span style=\"color:navy\">Part 6: Testing your Classifier</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have the means (centroid) for each word. Now let's see how well our test data performs. Recall that we will classify each data point according to the centroid that it is closest in Euclidean distance to. \n",
    "\n",
    "Before we perform classification, we need to do the same preprocessing to the test data that we did to the training data (enveloping, demeaning, projecting onto the PCA basis). You have already written most of the code for this part. However, note the difference in variable names as we are now working with test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at what our raw test data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the same number of readings for all words to be fair\n",
    "num_samples_test = min(np.shape(word1_raw_test)[0], np.shape(word2_raw_test)[0], np.shape(word3_raw_test)[0], np.shape(word4_raw_test)[0])\n",
    "word1_raw_test = word1_raw_test[:num_samples_test,:]\n",
    "word2_raw_test = word2_raw_test[:num_samples_test,:]\n",
    "word3_raw_test = word3_raw_test[:num_samples_test,:]\n",
    "word4_raw_test = word4_raw_test[:num_samples_test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot all test samples\n",
    "plt.plot(word1_raw_test.T)\n",
    "plt.show()\n",
    "plt.plot(word2_raw_test.T)\n",
    "plt.show()\n",
    "plt.plot(word3_raw_test.T)\n",
    "plt.show()\n",
    "plt.plot(word4_raw_test.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform enveloping and trimming of our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word1_processed_test = get_snippets(word1_raw_test, length, pre_length, threshold)\n",
    "plt.plot(word1_processed_test.T)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "word2_processed_test = get_snippets(word2_raw_test, length, pre_length, threshold)\n",
    "plt.plot(word2_processed_test.T)\n",
    "plt.show()\n",
    "word3_processed_test = get_snippets(word3_raw_test, length, pre_length, threshold)\n",
    "plt.plot(word3_processed_test.T)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "word4_processed_test = get_snippets(word4_raw_test, length, pre_length, threshold)\n",
    "plt.plot(word4_processed_test.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the data matrix by stacking all the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "processed_A_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will do something slightly different.**\n",
    "\n",
    "Previously, you projected data using some projection matrix with $ P(x - \\bar{x}) $, where $\\bar{x}$ is the mean vector.\n",
    "\n",
    "We can rewrite this operation as \n",
    "\n",
    "$$ P(x - \\bar{x}) = Px - P \\bar{x} = Px - \\bar{x}_{\\text{proj}} $$ \n",
    "$$ \\bar{x}_{\\text{proj}} = P \\bar{x} $$\n",
    "\n",
    "Why might we want to do this? We'll later perform these operations on our car. Our launchpads have limited memory, so we want to store as little as possible. Instead of storing a length $n$ vector $\\bar{x}$, we can precompute $ \\bar{x}_{\\text{proj}} $ (length 2 or 3) and store that instead!\n",
    "\n",
    "Compute $ \\bar{x}_{\\text{proj}} $ using the **same mean vector** as the one computed with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "projected_mean_vec = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project the test data onto the **same PCA basis** as the one computed with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "projected_A_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-mean the projected test data using the **`projected_mean_vec`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "proj = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the projections to see how well your test data clusters in this new basis. This will give you an idea of how well your test data will classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Uncomment this for 3 basis vectors\n",
    "fig=plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_3D(ax,[proj[:num_samples_test], proj[num_samples_test:2*num_samples_test], proj[2*num_samples_test:3*num_samples_test], proj[3*num_samples_test:4*num_samples_test]], view_from_top=False)\n",
    "plot_3D(ax,[np.array([centroid_list[0]]), np.array([centroid_list[1]]), np.array([centroid_list[2]]), np.array([centroid_list[3]])], False, '*', 300)\n",
    "fig.show\n",
    "'''\n",
    "\n",
    "fig=plt.figure(figsize=(10,7))\n",
    "plt.scatter(proj[0:num_samples_test,0], proj[0:num_samples_test,1], c=['blue'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_test:num_samples_test*2,0], proj[num_samples_test:num_samples_test*2,1], c=['red'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_test*2:num_samples_test*3,0], proj[num_samples_test*2:num_samples_test*3,1], c=['green'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples_test*3:num_samples_test*4,0], proj[num_samples_test*3:num_samples_test*4,1], c=['orange'], edgecolor='none')\n",
    "plt.legend(['word1', 'word2', 'word3', 'word4'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.scatter(centroid_list[:,0], centroid_list[:,1], c=['blue', 'red', 'green', 'orange'], marker='*', s=300)\n",
    "plt.legend(['word1', 'word2', 'word3', 'word4'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some idea of how our test data looks in this new basis, let's see how our data actually performs. Implement the classify function that takes in a data point (AFTER preprocessing is applied) and returns which word number it belongs to depending on which centroid the data point is closest in Euclidean distance to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(data_point):\n",
    "    \"\"\"Classifies a new voice recording into a word.\n",
    "    \n",
    "    Args:\n",
    "        data_point: new data point vector before demeaning and projection\n",
    "    Returns:\n",
    "        Word number (should be in {1, 2, 3, 4})\n",
    "    Hint:\n",
    "        Remember to use 'projected_mean_vec'!\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    projected_data_point = ...\n",
    "    demeaned = ...\n",
    "    # TODO: classify the demeaned data point by comparing against the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try out the classification function\n",
    "print(classify(processed_A_test[0,:])) # Modify to use other vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our goal is 80% accuracy for each word.** Write code to apply the `classify` function to each sample and compute the accuracy for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to classify the whole A matrix\n",
    "correct_counts = np.zeros(4)\n",
    "\n",
    "for (row_num, data) in enumerate(processed_A_test):\n",
    "    word_num = row_num // num_samples_test + 1\n",
    "    if classify(data) == word_num:\n",
    "        correct_counts[word_num - 1] += 1\n",
    "        \n",
    "for i in range(len(correct_counts)):\n",
    "    print(\"Percent correct of word {} = {}%\".format(i + 1, 100 * correct_counts[i] / num_samples_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='30px' align='left' src=\"http://inst.eecs.berkeley.edu/~ee16b/sp16/lab_pics/check.png\">\n",
    "\n",
    "## <span style=\"color:green\">CHECKOFF 2</span>\n",
    "\n",
    "<span style=\"color:green\">**Show your GSI that you've achieved 80% classification accuracy on your test data.** Your GSI will also check your PCA diagrams and code.</span>\n",
    "Run the Appendix code now so you have easy access to the printouts of the code next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appendix'></a>\n",
    "## <span style=\"color:navy\">Appendix: Formatting Vectors for Energia</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next week's lab, copy/paste the following printed code into **`classify.ino`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Paste the code below into 'CODE BLOCK PCA1':\")\n",
    "print(\"\")\n",
    "print(utils.format_constant_energia(\"SNIPPET_SIZE\", length))\n",
    "print(utils.format_constant_energia(\"PRELENGTH\", pre_length))\n",
    "print(utils.format_constant_energia(\"THRESHOLD\", threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Paste the code below into 'CODE BLOCK PCA2':\")\n",
    "print(\"\")\n",
    "print(utils.format_array_energia(\"pca_vec1\", new_basis[:, 0]))\n",
    "print(utils.format_array_energia(\"pca_vec2\", new_basis[:, 1]))\n",
    "# print(utils.format_array_energia(\"pca_vec3\", new_basis[:, 2]))   # Uncomment this line if you have 3 PCA vectors\n",
    "print(utils.format_array_energia(\"projected_mean_vec\", projected_mean_vec))\n",
    "print(utils.format_array_energia(\"centroid1\", centroids[0]))\n",
    "print(utils.format_array_energia(\"centroid2\", centroids[1]))\n",
    "print(utils.format_array_energia(\"centroid3\", centroids[2]))\n",
    "print(utils.format_array_energia(\"centroid4\", centroids[3]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
